# -*- coding: utf-8 -*-
"""B·∫£n sao c·ªßa Black_Friday_Sale

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CUyG1U5hqeSuB1zO8aFGq1YhjwVn-w-z
"""

from google.colab import files
uploaded = files.upload()

# ƒê·ªåC D·ªÆ LI·ªÜU
import pandas as pd
df = pd.read_csv('/content/Black_Friday_Sale.csv')
#check data
print("\nData information:")
print(df.info())
print("\nData Description:")
print(df.describe())

# df['Product_Category_2'] = df['Product_Category_2'].fillna(0) # Removed fillna(0)
# df['Product_Category_3'] = df['Product_Category_3'].fillna(0) # Removed fillna(0)
df = df.drop_duplicates()
print(f"Number of records remaining after prosessing: {len(df)}.")

import pandas as pd
import numpy as np

# 1. T·∫£i d·ªØ li·ªáu (N·∫øu df ch∆∞a ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a)
try:
    df = pd.read_csv('Black_Friday_Sale.csv')
except NameError:
    # N·∫øu l·ªói x·∫£y ra do df ch∆∞a ƒë∆∞·ª£c t·∫£i
    df = pd.read_csv('Black_Friday_Sale.csv')

# 2. X·ª≠ l√Ω NaN (ƒëi·ªÅn 0.0) cho c√°c c·ªôt danh m·ª•c ph·ª•
nan_cols = ['Product_Category_2', 'Product_Category_3']
df[nan_cols] = df[nan_cols].fillna(0.0)

# 3. K·ªπ thu·∫≠t ƒê·∫∑c tr∆∞ng: T·∫°o Ra Nh√≥m Tu·ªïi C·ªët L√µi (Age Tier)
# ƒê√ÇY L√Ä PH·∫¶N B·ªä THI·∫æU G√ÇY RA L·ªñI KEYERROR
def create_age_group_tier(age_str):
    if age_str in ['0-17', '18-25']:
        return 'Young_Adults'
    elif age_str in ['26-35', '36-45', '46-50']:
        return 'Middle_Age'
    else: # '51-55', '55+'
        return 'Seniors'

df['Age_Tier'] = df['Age'].apply(create_age_group_tier)
print("‚úÖ ƒê√£ t·∫°o c·ªôt 'Age_Tier' th√†nh c√¥ng.")
# -----------------------------------------------------


# --- TI·∫æN H√ÄNH PH√ÇN T√çCH SAU KHI S·ª¨A L·ªñI ---
print("\n--- üìà Ph√¢n t√≠ch Mua h√†ng Trung b√¨nh theo Nh√≥m Tu·ªïi C·ªët l√µi (Age Tier) ---")

# D√πng c√∫ ph√°p truy·ªÅn th·ªëng (Ph∆∞∆°ng ph√°p 1: T∆∞∆°ng th√≠ch h∆°n)
age_analysis = df.groupby('Age_Tier')['Purchase'].agg(
    [
        'count',  # T·ªïng s·ªë l·∫ßn giao d·ªãch
        'mean',   # Gi√° tr·ªã mua h√†ng trung b√¨nh
        'median', # Gi√° tr·ªã mua h√†ng trung v·ªã
        'sum'     # T·ªïng doanh s·ªë
    ]
)

# ƒê·ªïi t√™n c·ªôt sau khi t·ªïng h·ª£p ƒë·ªÉ d·ªÖ ƒë·ªçc h∆°n
age_analysis.columns = ['Count_Records', 'Mean_Purchase', 'Median_Purchase', 'Total_Purchase']
age_analysis = age_analysis.sort_values(by='Mean_Purchase', ascending=False)

# ƒê·ªãnh d·∫°ng hi·ªÉn th·ªã
pd.options.display.float_format = '{:,.2f}'.format
print(age_analysis)

import pandas as pd

# Gi·∫£ ƒë·ªãnh df ƒë√£ ƒë∆∞·ª£c t·∫£i v√† ti·ªÅn x·ª≠ l√Ω t·ª´ c√°c b∆∞·ªõc tr∆∞·ªõc.

# --- 1. Ph√¢n t√≠ch T·∫ßn su·∫•t Theo Gi·ªõi t√≠nh ---
print("\n--- üìä T·∫ßn su·∫•t Kh√°ch h√†ng theo Gi·ªõi t√≠nh ---")
# T√≠nh t·ªïng s·ªë giao d·ªãch (records) theo Gi·ªõi t√≠nh v√† chuy·ªÉn th√†nh t·ª∑ l·ªá ph·∫ßn trƒÉm
gender_counts = df['Gender'].value_counts()
gender_percentage = df['Gender'].value_counts(normalize=True).mul(100).round(2)
gender_distribution = pd.DataFrame({
    'Total Transactions': gender_counts,
    'Percentage (%)': gender_percentage
})
# ƒê·ªïi nh√£n ch·ªâ m·ª•c cho d·ªÖ hi·ªÉu
gender_distribution.index = ['Male (M)', 'Female (F)']
print(gender_distribution)

# --- 2. Ph√¢n t√≠ch T·∫ßn su·∫•t Theo ƒê·ªô tu·ªïi ---
print("\n--- üìà T·∫ßn su·∫•t Kh√°ch h√†ng theo ƒê·ªô tu·ªïi ---")
# T√≠nh t·ªïng s·ªë giao d·ªãch v√† t·ª∑ l·ªá ph·∫ßn trƒÉm theo nh√≥m Age g·ªëc
age_distribution = df['Age'].value_counts().sort_index()
age_percentage = df['Age'].value_counts(normalize=True).mul(100).round(2).sort_index()
age_summary = pd.DataFrame({
    'Age Group': age_distribution.index,
    'Total Transactions': age_distribution.values,
    'Percentage (%)': age_percentage.values
})
print(age_summary)

# --- 3. Ph√¢n t√≠ch Mua h√†ng Trung b√¨nh Theo Gi·ªõi t√≠nh v√† Nh√≥m tu·ªïi (Ph√¢n kh√∫c S√¢u h∆°n) ---
print("\n--- üéØ Mua h√†ng Trung b√¨nh Theo Gi·ªõi t√≠nh v√† ƒê·ªô tu·ªïi (Ph√¢n kh√∫c S√¢u) ---")
# S·ª≠ d·ª•ng c·∫£ hai c·ªôt ph√¢n lo·∫°i ƒë·ªÉ t·ªïng h·ª£p
gender_age_pivot = df.pivot_table(
    values='Purchase',
    index='Age',         # H√†ng l√† Nh√≥m tu·ªïi
    columns='Gender',    # C·ªôt l√† Gi·ªõi t√≠nh
    aggfunc='mean'       # Gi√° tr·ªã l√† Mua h√†ng Trung b√¨nh
).sort_index()
print(gender_age_pivot)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# --- T·∫¢I V√Ä TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU ---
# (ƒê·∫£m b·∫£o df ƒë√£ ƒë∆∞·ª£c t·∫£i v√† ti·ªÅn x·ª≠ l√Ω, t√¥i l·∫∑p l·∫°i c√°c b∆∞·ªõc c∆° b·∫£n ƒë·ªÉ ƒë·∫£m b·∫£o code ho·∫°t ƒë·ªông ƒë·ªôc l·∫≠p)
df = pd.read_csv('Black_Friday_Sale.csv')
nan_cols = ['Product_Category_2', 'Product_Category_3']
df[nan_cols] = df[nan_cols].fillna(0.0)


# --- VISUALIZATION M·ªöI: BI·ªÇU ƒê·ªí C·ªòT NH√ìM (GROUPED BAR CHART) ---
plt.figure(figsize=(12, 7))

# S·ª≠ d·ª•ng seaborn.barplot ƒë·ªÉ tr·ª±c quan h√≥a m·ª©c chi ti√™u trung b√¨nh
# Ph√¢n nh√≥m theo Age (tr·ª•c X) v√† Gender (m√†u s·∫Øc/hue)
sns.barplot(
    data=df.sort_values('Age'), # S·∫Øp x·∫øp d·ªØ li·ªáu theo Age ƒë·ªÉ c√°c nh√≥m tu·ªïi li·ªÅn k·ªÅ nhau
    x='Age',                     # Nh√≥m ch√≠nh: ƒê·ªô tu·ªïi
    y='Purchase',                # Gi√° tr·ªã: Mua h√†ng Trung b√¨nh
    hue='Gender',                # Nh√≥m ph·ª•: Gi·ªõi t√≠nh
    palette={'M': '#1f77b4', 'F': '#ff7f0e'}, # M√†u s·∫Øc t√πy ch·ªânh (Xanh cho Nam, Cam cho N·ªØ)
    errorbar=None                # Lo·∫°i b·ªè thanh l·ªói (error bar) ƒë·ªÉ bi·ªÉu ƒë·ªì s·∫°ch h∆°n
)

# Th√™m nh√£n v√† ti√™u ƒë·ªÅ
plt.title('Average Purchase by Age Group and Gender', fontsize=16)
plt.xlabel('Age Group', fontsize=12)
plt.ylabel('Average Purchase (USD)', fontsize=12)

# ƒê·ªãnh d·∫°ng nh√£n ch√∫ gi·∫£i
plt.legend(title='Gender', labels=['Male (M)', 'Female (F)'])
plt.grid(axis='y', linestyle='--', alpha=0.6)
plt.tight_layout()

# L∆∞u bi·ªÉu ƒë·ªì
plt.savefig('age_gender_purchase_comparison.png')
print("‚úÖ Bi·ªÉu ƒë·ªì so s√°nh m·ª©c mua h√†ng trung b√¨nh theo Gi·ªõi t√≠nh v√† ƒê·ªô tu·ªïi ƒë√£ ƒë∆∞·ª£c t·∫°o v√† l∆∞u d∆∞·ªõi d·∫°ng 'age_gender_purchase_comparison.png'.")

import pandas as pd

# --- T·∫¢I V√Ä TI·ªÄN X·ª¨ L√ù B·∫ÆT BU·ªòC ---
df = pd.read_csv('Black_Friday_Sale.csv')
nan_cols = ['Product_Category_2', 'Product_Category_3']
df[nan_cols] = df[nan_cols].fillna(0.0)


# --- PH√ÇN T√çCH MUA H√ÄNG TRUNG B√åNH THEO TH√ÄNH PH·ªê V√Ä GI·ªöI T√çNH ---
print("\n--- üèôÔ∏è M·ª©c Chi ti√™u Trung b√¨nh (USD) theo Th√†nh ph·ªë v√† Gi·ªõi t√≠nh ---")

# T·∫°o b·∫£ng pivot (Ma tr·∫≠n hai chi·ªÅu)
city_gender_pivot = df.pivot_table(
    values='Purchase',      # Gi√° tr·ªã: Mua h√†ng
    index='City_Category',  # H√†ng: Ph√¢n lo·∫°i Th√†nh ph·ªë (A, B, C)
    columns='Gender',       # C·ªôt: Gi·ªõi t√≠nh (F, M)
    aggfunc='mean'          # H√†m t·ªïng h·ª£p: Trung b√¨nh
)

# ƒê·ªãnh d·∫°ng hi·ªÉn th·ªã ti·ªÅn t·ªá
pd.options.display.float_format = '{:,.2f}'.format
print(city_gender_pivot)

# Visualization 3: Bar Chart - Total Purchase by City Category
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# --- T·∫¢I V√Ä TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU --- (ƒë·∫£m b·∫£o df ƒë∆∞·ª£c t·∫£i v√† x·ª≠ l√Ω n·∫øu code ch·∫°y ƒë·ªôc l·∫≠p)
df = pd.read_csv('Black_Friday_Sale.csv')
nan_cols = ['Product_Category_2', 'Product_Category_3']
df[nan_cols] = df[nan_cols].fillna(0.0)

# Kh·∫Øc ph·ª•c l·ªói: T·∫°o c√°c c·ªôt 'City_A', 'City_B', 'City_C' b·∫±ng One-Hot Encoding
df = pd.get_dummies(df, columns=['City_Category'], prefix='City', dtype=int)

plt.figure(figsize=(8, 6))
city_purchase = df[['City_A', 'City_B', 'City_C']].multiply(df['Purchase'], axis=0).sum() / 1000
sns.barplot(x=city_purchase.index, y=city_purchase.values)
plt.title('Total Purchase by City Category')
plt.xlabel('City Category')
plt.ylabel('Total Purchase (K$)')
plt.savefig('city_purchase.png')
plt.show()

# Visualization 4: Pie Chart - Product Category 1 Distribution
plt.figure(figsize=(8, 8))
product_cat1_counts = df['Product_Category_1'].value_counts()
# Filter categories with significant counts (>5000)
product_cat1_counts = product_cat1_counts[product_cat1_counts > 5000]
plt.pie(product_cat1_counts, labels=[f'Category {x}' for x in product_cat1_counts.index], autopct='%1.1f%%', startangle=140)
plt.title('Product Category 1 Distribution')
plt.savefig('product_cat1_distribution.png')
plt.show()

# Visualization 5: Line Chart - Total Purchase by Stay in Current City
plt.figure(figsize=(8, 6))
stay_purchase = df.groupby('Stay_In_Current_City_Years')['Purchase'].sum() / 1000
plt.plot(stay_purchase.index, stay_purchase.values, marker='o')
plt.title('Total Purchase by Years in Current City')
plt.xlabel('Years in Current City')
plt.ylabel('Total Purchase (K$)')
plt.savefig('stay_purchase.png')
plt.show()

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import pandas as pd

# 1. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu (L√†m s·∫°ch v√† M√£ h√≥a)
df_clustering = df.copy()

# ƒêi·ªÅn gi√° tr·ªã thi·∫øu b·∫±ng Mode (R√∫t g·ªçn d√πng fillna)
cols_to_fix = ['Product_Category_2', 'Product_Category_3']
df_clustering[cols_to_fix] = df_clustering[cols_to_fix].fillna(df_clustering[cols_to_fix].mode().iloc[0])

# One-hot encoding v√† lo·∫°i b·ªè c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt (User_ID, Product_ID) ngay l·∫≠p t·ª©c
# drop_first=True gi√∫p gi·∫£m ƒëa c·ªông tuy·∫øn (kh√¥ng b·∫Øt bu·ªôc nh∆∞ng t·ªët cho m√¥ h√¨nh)
X = pd.get_dummies(df_clustering.drop(['User_ID', 'Product_ID'], axis=1),
                   columns=['Gender', 'Age', 'Stay_In_Current_City_Years'],
                   dtype=int)

# 2. Chu·∫©n h√≥a d·ªØ li·ªáu
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. Hu·∫•n luy·ªán KMeans
kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
df_clustering['Cluster'] = kmeans.fit_predict(X_scaled)

# 4. Hi·ªÉn th·ªã k·∫øt qu·∫£
print("Clustering results (first 5 rows):")
cols_show = ['User_ID', 'Occupation', 'Marital_Status', 'Purchase', 'Cluster']
print(df_clustering[cols_show].head())

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import pandas as pd # Ensure pandas is imported for get_dummies

# Prepare the data for modeling
X = df.drop(['Purchase', 'User_ID', 'Product_ID'], axis=1)
y = df['Purchase']

# Identify categorical columns for one-hot encoding
categorical_cols = ['Gender', 'Age', 'Stay_In_Current_City_Years']

# Apply one-hot encoding to convert categorical features into numerical ones
X = pd.get_dummies(X, columns=categorical_cols, drop_first=True, dtype=int)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the linear regression model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = lr_model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)

print(f"Mean Squared Error: {mse:.4f}")
print(f"R-squared: {r2:.4f}")
print(f"Mean Absolute Error: {mae:.4f}")

wcss = kmeans.inertia_
wcss_adjusted = wcss * 0.001
print(f"WCSS (Sum of squares within cluster): {wcss_adjusted:.2f}")